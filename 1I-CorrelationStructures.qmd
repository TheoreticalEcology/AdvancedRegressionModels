# Correlation structures {#correlation}

```{=html}
<!-- Put this here (right after the first markdown headline) and only here for each document! -->
<script src="./scripts/multipleChoice.js"></script>
```

## General Idea

Except for the random effects, we have so far assumed that observations are independent. However, there are a number of other common correlation structures that we may want to consider. Here a visualization from <a href="https://onlinelibrary.wiley.com/doi/10.1111/ecog.02881" target="_blank" rel="noopener">Roberts et al., 2016</a> (reproduced as OA, copyright: the authors).

```{r chunk_chapter6_chunk0, echo=FALSE, out.width="100%", out.height="100%"}
knitr::include_graphics(c("images/correlation.png"))
```

The figure shows random effects, and a number of other correlation structures. In random effects, residuals are structured in groups. All of the other three correlation structures discussed here are different. They are distance-based correlations between data points. Distance is expressed, e.g., by:

* Spatial distance.
* Temporal distance.
* Phylogenetic distance.

For either of these structures, there can be two phenomena that lead to correlations:

1. There can be a **trend** in the given space (e.g. time, space), which we have to remove first.
2. After accounting for the trend, there can be a so-called **autocorrelation** between data points.

The idea of the so-called **conditional autoregressive** (CAR) structures is, that we make parametric assumptions for how the correlation between data points falls off with distance. Then, we fit the model with this structure.

Similar as for the variance modelling, we can add this structures

* either in `nlme::gls`{.R}, see <a href="https://stat.ethz.ch/R-manual/R-devel/library/nlme/html/corClasses.html" target="_blank" rel="noopener">https://stat.ethz.ch/R-manual/R-devel/library/nlme/html/corClasses.html</a>,
* or in `glmmTMB`{.R}, see <a href="https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html" target="_blank" rel="noopener">https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html</a>.

The following pages provide examples and further comments on how to do this.


## Temporal Correlation Structures

In principle, spatial and temporal correlation are quite similar, there are 2 options we can have:

1. There is a spatial trend in time / space, which creates a correlation in space / time.
2. There truly is a spatial correlation, after accounting for the trend.

Unfortunately, the distinction between a larger trend and a correlation is quite fluid. Nevertheless, one should always first check for and remove the trend, typically by including time/space as a predictor, potentially in a flexible way (GAMs come in handy). After this is done, we can fit a model with a temporally/spatially correlated error.

As our first example, I look at the hurricane study from yesterday, which is, after all, temporal data. This data set is located in `DHARMa`{.R}.

```{r chunk_chapter6_chunk1, echo=TRUE, eval=TRUE}
library(glmmTMB)
library(DHARMa)

originalModelGAM = glmmTMB(alldeaths ~ scale(MasFem) *
                          (scale(Minpressure_Updated_2014) + scale(NDAM)),
                           data = hurricanes, family = nbinom2)

# Residual checks with DHARMa.
res = simulateResiduals(originalModelGAM)
plot(res)

# No significant deviation in the general plot, but try this, which was highlighted by
# https://www.theguardian.com/science/grrlscientist/2014/jun/04/hurricane-gender-name-bias-sexism-statistics
plotResiduals(res, hurricanes$NDAM)

# We also find temporal autocorrelation.
res2 = recalculateResiduals(res, group = hurricanes$Year)
testTemporalAutocorrelation(res2, time = unique(hurricanes$Year))
```

A second example from Pinheiro and Bates, pp. 255-258. The data originates from Vonesh and Carter (1992), who describe data measured on high-flux hemodialyzers to assess their in vivo ultrafiltration characteristics. The ultrafiltration rates (in mL/hr) of 20 high-flux dialyzers were measured at seven different transmembrane pressures (in dmHg). The in vitro evaluation of the dialyzers used bovine blood at flow rates of either 200~dl/min or 300~dl/min. The data, are also analyzed in Littell, Milliken, Stroup and Wolfinger (1996).

See `?Dialyzer`{.R} for explanation of the variables (data comes with the package `nlme`.{R}).

The data highlights the flexibility of gls for structured `( 1| subject)`{.R} temporal data. Unfortunately, `nlme`.{R} does not interface with `DHARMa`.{R}.

```{r chunk_chapter6_chunk2, echo=TRUE, eval=TRUE}
library(nlme)

fm1Dial.gls = gls(rate ~(pressure + I(pressure^2) + I(pressure^3) + I(pressure^4))*QB,
                  data = Dialyzer)
plot(fm1Dial.gls)
fm2Dial.gls = update(fm1Dial.gls, weights = varPower(form = ~ pressure))
plot(fm2Dial.gls)
fm3Dial.gls = update(fm2Dial.gls, corr = corAR1(0.771, form = ~ 1 | Subject))
summary(fm3Dial.gls)
```


## Spatial Correlation Structures

We will use a data set with the thickness of coal seams, that we try to predict with a spatial (soil) predictor. Read in data

```{r chunk_chapter6_chunk4, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
library(EcoData)
library(DHARMa)
library(gstat)

plot(thick ~ soil, data = thickness)
fit = lm(thick ~ soil, data = thickness)
summary(fit)

# Quantile residuals are not actually needed in this case but
# DHARMa includes a test for spatial autocorrelation which
# will save us coding time
res = simulateResiduals(fit)
testSpatialAutocorrelation(res, x = thickness$north, y = thickness$east)

# Looking also at the directional variogram
tann.dir.vgm = variogram(residuals(fit) ~ 1,
                         loc =~ east + north, data = thickness,
                         alpha = c(0, 45, 90, 135))
plot(tann.dir.vgm)
```

To remove the spatial trend, we can use a 2d-spine, called a tensor spline:


```{r chunk_chapter6_chunk5, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
library(mgcv)
library(modEvA)

fit1 = gam(thick ~ soil + te(east, north) , data = thickness)
summary(fit1)
plot(fit1, pages = 0, lwd = 2)

res = simulateResiduals(fit1)
testSpatialAutocorrelation(res, x = thickness$north, y = thickness$east)
```

Almost the same, but simpler:

```{r chunk_chapter6_chunk6, echo=TRUE, eval=TRUE}
fit = lm(thick ~ soil + north + I(north^2), data = thickness)
```

Alternatively, fit an autoregressive model. Of course, both options can be combined.

```{r chunk_chapter6_chunk7, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
fit2 = gls(thick ~ soil , correlation = corExp(form =~ east + north) , data = thickness)
summary(fit2)

fit1 = gls(thick ~ soil + north + I(north^2), data = thickness)

anova(fit1, fit2)
```



:::{.callout-caution icon=false}
#### Plant counts in Regensburg
Use the dataset EcoData::plantcounts. Our scientific question is if richness ~ agrarea. Help on the dataset, as well as a few initial plots, is in the help of ?plantcounts.

This is count data, so start with a Poisson or Neg Binom GLM. The quadrats are not all equally sized, so you should include an offest to account for area. Then, check for spatial autocorrelation.

If you find autocorrelation that cannot be removed with a gam, the problem is that the gls function that we have used so far only extends lm, and not glm models. In this case, you can either read up in https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html how to specify a spatial covariance in glmmTMB, or just log transform your counts + 1, and fit a gls. 
:::

:::{.callout-tip collapse="true" appearance="minimal" icon=false }
#### Solution

```{r message=FALSE, warning=FALSE}
?EcoData::plantcounts

plants_sf <- plantcounts
str(plants_sf)
plants_sf$agrarea_scaled <- scale(plants_sf$agrarea)

plants_sf$longitude <- plants_sf$lon
plants_sf$latitude <- plants_sf$lat
library(sf)
plants_sf <- sf::st_as_sf(plants_sf, coords = c('longitude', 'latitude'), crs
                          = st_crs("+proj=longlat +ellps=bessel
                                   +towgs84=606,23,413,0,0,0,0 +no_defs"))

library(mapview)
mapview(plants_sf["richness"], map.types = "OpenTopoMap")

fit <-  glmmTMB::glmmTMB(richness ~ agrarea_scaled + offset(log(area)),
                family = nbinom1, data = plants_sf)
summary(fit)

library(DHARMa)
res <- simulateResiduals(fit)
plot(res)
testSpatialAutocorrelation(res, x = plants_sf$lon, y =  plants_sf$lat)

fit2<-mgcv::gam(richness ~ agrarea_scaled + te(lon, lat),
            offset(log(area)), family = nb, data = plants_sf)
summary(fit2)
plot(fit2)

res <- simulateResiduals(fit2)
plot(res)
testSpatialAutocorrelation(res, x = plants_sf$lon, y =  plants_sf$lat)
```


:::



:::{.callout-caution icon=false}
#### The snouter data

Fit one of the responses in the snouter datset against the predictors rain + djungle (see ?snouter). Check for spatial autocorrelation and proceed to fitting a spatial model if needed. See the data set's help for details on the variables.
:::

:::{.callout-tip collapse="true" appearance="minimal" icon=false }
#### Solution

```{r chunk_chapter6_task_0, message=FALSE, warning=FALSE}
library(EcoData)
str(snouter)
```
:::


## Phylogenetic Structures (PGLS)

This is mostly taken from <a href="https://lukejharmon.github.io/ilhabela/instruction/2015/07/03/PGLS/" target="_blank" rel="noopener">https://lukejharmon.github.io/ilhabela/instruction/2015/07/03/PGLS/</a>. The two datasets associated with this example are in the `EcoData`{.R} package.

Perform analysis:

```{r chunk_chapter6_chunk8, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
library(EcoData)
library(ape)
library(geiger)
library(nlme)
library(phytools)
library(DHARMa)
```

To plot the phylogenetic tree, use

```{r chunk_chapter6_chunk9, eval=FALSE, fig.width=8, fig.height=18}
plot(anolisTree)
```

Regress species traits

```{r}
# Check whether names are matching in both files.
name.check(anolisTree, anolisData)

# Plot traits.
plot(anolisData[, c("awesomeness", "hostility")])

plot(hostility ~ awesomeness, data = anolisData)
fit = lm(hostility ~ awesomeness, data = anolisData)
summary(fit)
abline(fit)
```


Check for phylogenetic signal in residuals.

```{r}
# Calculate weight matrix for phylogenetic distance.
w = 1/cophenetic(anolisTree)
diag(w) = 0

Moran.I(residuals(fit), w)
```

Conclusion: signal in the residuals, a normal lm will not work.

You can also check with DHARMa, using this works also for GLMMs

```{r}
res = simulateResiduals(fit)
testSpatialAutocorrelation(res, distMat = cophenetic(anolisTree))
```

An old-school method to deal with the problem are the so-called **Phylogenetically Independent Contrasts** (PICs) (Felsenstein, J. (1985) "Phylogenies and the comparative method". American Naturalist, 125, 1–15.). The idea here is to transform your data in a way that an lm is still appropriate. For completeness, I show the method here.

```{r chunk_chapter6_chunk12, echo=TRUE, eval=TRUE}
# Extract columns.
host = anolisData[, "hostility"]
awe = anolisData[, "awesomeness"]

# Give them names.
names(host) = names(awe) = rownames(anolisData)

# Calculate PICs.
hPic = pic(host, anolisTree)
aPic = pic(awe, anolisTree)

# Make a model.
picModel = lm(hPic ~ aPic - 1)

summary(picModel) # Yes, significant.

# plot results.
plot(hPic ~ aPic)
abline(a = 0, b = coef(picModel))
```

Now, new school, with a PGLS

```{r chunk_chapter6_chunk13, echo=TRUE, eval=TRUE}
pglsModel = gls(hostility ~ awesomeness,
                 correlation = corBrownian(phy = anolisTree, form =~ species),
                 data = anolisData, method = "ML")
summary(pglsModel)
coef(pglsModel)
plot(hostility ~ awesomeness, data = anolisData)
abline(pglsModel, col = "red")
```

OK, same result, but PGLS is WAY more flexible than PICs.
For example, we can include a discrete predictor:

```{r chunk_chapter6_chunk14, echo=TRUE, eval=TRUE}
pglsModel2 = gls(hostility ~ ecomorph,
                    correlation = corBrownian(phy = anolisTree, form =~ species),
                    data = anolisData, method = "ML")
summary(pglsModel2)
anova(pglsModel2)

# We can even include multiple predictors:

pglsModel3 = gls(hostility ~ ecomorph * awesomeness,
                correlation = corBrownian(phy = anolisTree, form =~ species),
                data = anolisData, method = "ML")
summary(pglsModel3)
anova(pglsModel3)
```

We can also assume that the error structure follows an **Ornstein-Uhlenbeck** model rather than **Brownian motion**. When trying this, however, I noted that the model does not converge due to a scaling problem. We can do a quick fix by making the branch lengths longer. This will not affect the analysis other than rescaling a nuisance parameter.

```{r chunk_chapter6_chunk15, echo=TRUE, eval=TRUE}
tempTree = anolisTree
tempTree$edge.length = tempTree$edge.length * 100
pglsModelLambda = gls(hostility ~ awesomeness,
                      correlation = corPagel(1, phy = tempTree, fixed = FALSE,
                                             form =~ species),
                      data = anolisData, method = "ML")
summary(pglsModelLambda)

pglsModelOU = gls(hostility ~ awesomeness,
                   correlation = corMartins(1, phy = tempTree, form =~ species),
                   data = anolisData)
summary(pglsModelOU)
```

Other example: <a href="http://schmitzlab.info/pgls.htmla" target="_blank" rel="noopener">http://schmitzlab.info/pgls.html</a>.

For fitting PGLS with various models, you should also consider the `caper`{.R} package.


:::{.callout-caution icon=false}
#### Excercise

Download the following two datasets

http://www.phytools.org/Cordoba2017/data/BarbetTree.nex
http://www.phytools.org/Cordoba2017/data/Barbetdata.csv

These data are from a study by Corboda et al., 2017, which examined the influence of environmental factors on the evolution of song in an group of Asian bird species called “barbets.” The code reads in and cleans the data:

```{r, eval = T}
library(ape)
dat<-read.csv(url("http://www.phytools.org/Cordoba2017/data/Barbetdata.csv"),header=TRUE,row.names=1)
tree<-read.nexus(url("http://www.phytools.org/Cordoba2017/data/BarbetTree.nex"))

dat$species = row.names(dat)
plot(tree)

# dropping species in the phylogeny for which we don't have data
obj<-geiger::name.check(tree,dat)
reducedTree<-drop.tip(tree, obj$tree_not_data)
geiger::name.check(reducedTree,dat)
```

Task: Check if there is a relationship between altitude at which a species is found and the length of the note in its song, which uses the variables Lnote~Lnalt
:::

:::{.callout-tip collapse="true" appearance="minimal" icon=false }
#### Solution

```{r}
plot(Lnote~Lnalt, data = dat)
fit <- lm(Lnote~ scale(Lnalt), data = dat)
summary(fit)
library(effects)
plot(allEffects(fit,partial.residuals = T))
```

Bit of a misfit, to get a good fit, after playing around, I added an interaction with a quadratic effect - you can probably also find other solutions. 

```{r}
fit <- lm(Lnote~ scale(Lnalt) * I(scale(Lnalt)^2), data = dat)
summary(fit)
plot(allEffects(fit,partial.residuals = T))
```

Now, with a more complex polynomial for Lnalt, how to we see if there is an overall effect of Lnalt? Easiest option is to do a LRT:

```{r}
fit0 = lm(Lnote~ 1, data = dat)
anova(fit0, fit)
```

Check residuals for phylogenetic correlation

```{r}
w = 1/cophenetic(reducedTree)
diag(w) = 0
Moran.I(residuals(fit), w)
```

Nothing! So we could leave the model as it is. Just for completeness, fit the same comparison with a PGLS, effect remains significant, but p-value a bit larger.

```{r}
fit <- gls(Lnote~ scale(Lnalt) * I(scale(Lnalt)^2), 
           correlation = corBrownian(phy = reducedTree, 
                                     form =~ species), data = dat, 
           method = "ML")

fit0 <- gls(Lnote~ 1, 
           correlation = corBrownian(phy = reducedTree, 
                                     form =~ species), data = dat, 
           method = "ML")

anova(fit0, fit)
```

Addition: what would happen if we do the same with a misspecified model? Have a look at the p-values of the fitted models. Can you explain what's going on here?

```{r}
fit <- lm(Lnote~ scale(Lnalt), data = dat)
summary(fit)

plot(allEffects(fit, partial.residuals = T))

w = 1/cophenetic(reducedTree)
diag(w) = 0
Moran.I(residuals(fit), w)

fit <- gls(Lnote~ scale(Lnalt), 
           correlation = corBrownian(phy = reducedTree, 
                                     form =~ species), data = dat, 
           method = "ML")
summary(fit)
```

The observation is that the PGLS effect estimate is significant while normal lm is not. The reason is probably that the PGLS is re-weighting residuals, and it seems that in this case, the re-weighting is changing the slope. What we learn by this example is that a PGLS can increase significance, and in this case I would argue wrongly so, as we have no indication that there is a phylogenetic signal. I would therefore NOT recommend to blindly fit PGLS, but rather test first if a PGLS is needed, and only then apply.  
:::




### Covariance structures in glmmTMB

gls only allows normally distributed responses. For GLMMs, you can use glmmTMB, which has (experimental) support for spatial, temporal or phylogenetic covariance structures on the REs. If you want to specific residual autocorrelation, you can create and observation-level RE and specify the covariance structure there. Take one of the examples that we had before (e.g. plantcount) and try to fit a spatial covariance with glmmTMB, using the tutorial here https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html

Alternative packages for spatial models are MASS::glmmPQL, BRMS, or INLA. 


