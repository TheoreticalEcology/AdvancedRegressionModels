---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Getting Started

## Organization of this book

The aim of this book is to introduce you to the main techniques and concepts that are used when performing regression analyses in applied settings. This book is organized in three parts:

1.  **Modelling the mean:** The first part of this book is focusing on how to model the mean response as a function of the one or several predictor variables. For this chapter, we will mainly stick to the assumptions of the linear regression, which is that residuals are i.i.d. normally distributed. Topics we will cover here are linear regression, ANOVA and mixed models
2.  **Model Choice** The second part covers model choice, including how to handle missing data, model selection, causal inference and non-parametric methods
3.  **Modelling the Distribution** The third part of the book is about modelling different residual distributions. We will relax the iid normal assumptions of the LM, and move to GLMs and modelling variance and correlation of residuals.

## Your R System

In this course, we work with the combination of R + RStudio.

-   R is the calculation engine that performs the computations.
-   RStudio is the editor that helps you sending inputs to R and collect outputs.

Make sure you have a recent version of R + RStudio installed on your computer. If you have never used RStudio, <a href="https://videocampus.sachsen.de/video/First-steps-with-R-and-RStudio/528e5d164219f2d07e32a51736c3f7d1" target="_blank" rel="noopener">here</a> is a good video introducing the basic system and how R and RStudio interact.

## Libraries that you will need

The R engine comes with a number of base functions, but one of the great things about R is that you can extend these base functions by libraries that can be programmed by anyone. In principle, you can install libraries from any website or file. In practice, however, most commonly used libraries are distributed via two major repositories. For statistical methods, this is **CRAN**, and for bioinformatics, this is **Bioconductor**.

::: {.callout-tip collapse="true"}
#### Click to see more on installing libraries in R

To install a package from a library, use the command

```{r chunk_chapter2_0, eval=FALSE, purl=FALSE}
install.packages(LIBRARY)
```

Exchange "LIBRARY" with the name of the library you want to install. The default is to search the package in CRAN, but you can specify other repositories or file locations in the function. For Windows / Mac, R should work out of the box. For other UNIX based systems, may also need to install

```         
build-essential
gfortran
libmagick++-dev
r-base-dev
cmake
```

If you are new to installing packages on Debian / Ubuntu, etc., type the following:

```         
sudo apt update && sudo apt install -y --install-recommends build-essential gfortran libmagick++-dev r-base-dev cmake
```
:::

In this book, we will often use data sets from the `EcoData`{.R} package, which is not on CRAN, but on a GitHub page. To install the package, if you don't have the devtools package installed already, first install devtools from CRAN by running

```{r, eval=FALSE}
install.packages("devtools")
```

Then install the EcoData package via

```{r chunk_chapter2_2, eval=FALSE}
devtools::install_github(repo = "TheoreticalEcology/EcoData",
                         dependencies = T, build_vignettes = T)
```

For your convenience, the EcoData installation also forces the installation of most of the packages needed in this book, so this may take a while. If you want to load only the EcoData package, or if you encounter problems during the install, set `dependencies = F, build_vignettes = F`.

## Assumed R knowledge

As mentioned in the preface, this book assumes that you have basic knowledge about data manipulation (reading in data, removing or selecting columns or rows, calculating means per group etc.) and plotting in R. Note that for both purposes, there are currently two main schools in the R environment which do the same things, but with very different syntax:

1.  **base R**, which uses functions such as `plot()`, `apply()`, `aggregate()`
2.  **tidyverse**, with packages such as **dplyr** and **ggplot2**, which provide functions such as `mutate()`, `filter()` and heavily rely on the `%>%` pipe operator.

There are many opinions about advantages and disadvantages of the two schools. I'm agnostic about this, or more precisely, I think you should get to know both schools and then decide based on the purpose. I see advantages of tidyverse in particular for data manipulation, while I often prefer baseR plots over ggplot2. To keep it simple, however, all code in this course uses base R.

::: callout-note
The tidyverse framework is currently trying to expand to the tasks of statistical / machine learning models as well, trying to streamline statistical workflows. While this certainly has a lot of potential, I don't see it as general / mature enough to recommend it as a default for the statistical workflow.
:::

## Recap basic R programming

In the remainder of this section, I will summarize basic plots and data manipulations skills in R, as they would be taught in an introductory R course (for example [here](https://theoreticalecology.github.io/DataScienceInR/)). Please read through them and make sure you know these commands in advance of the course. At the end of this part, there is a small exercise about data manipulation. If you are confindent that you can do it, you can also go there directly without reading the content of this section. 

### Representing Data in R

#### Exploring Data Structures

A fundamental requirement for working with data is representing it in a computer. In R, we can either read in data (e.g. with functions such as read.table()), or we can assign variables certain values. For example, if I type

```{r chunk_chapter2_3}
x <- 1
```

the variable x now contains some data, namely the value 1, and I can use x in as a placeholder for the data it contains in further calculations.

Alternatively to the \<- operator, you can also use = (in all circumstances that you are likely to encounter, it's the same).

```{r chunk_chapter2_4}
x = 1
```

If you have worked with R previously, this should all be familiar to you, and you should also know that the commands

```{r chunk_chapter2_5, eval=FALSE}
class(x)
dim(x)
str(x)
```

allow you to explore the structure of variables and the data they contain. Ask yourself, or discuss with your partner(s):

::: {.callout-caution icon="false"}
#### Excercise

What is the meaning of the three functions, and what is the structure / properties of the following data types in R:

-   Atomic types (which atomic types exist),
-   list,
-   vector,
-   data.frame,
-   matrix,
-   array.
:::

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Solution

Atomic types: e.g. numeric, factor, boolean ...; List can have severa tyes, vector not! data.frame is list of vectors. matrix is 2-dim array, array can have any dim, only one type.
:::

::: {.callout-caution icon="false"}
#### Excercise

What is the data type of the iris data set, which is built-in in R under the name

```{r chunk_chapter2_6, eval=FALSE}
iris
```
:::

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Solution

Iris, like most simple datasets, is of type data.frame
:::

#### Dynamic Typing

R is a dynamically typed language, which means that the type of variables is determined automatically depending on what values you supply. Try this:

```{r chunk_chapter2_7, eval=FALSE}
x = 1
class(x)
x = "dog"
class(x)
```

This also works if a data set already exists, i.e. if you assign a different value, the type will automatically be changed. Look at what happens when we assign a character value to a previously numeric column in a data.frame:

```{r chunk_chapter2_8, eval=FALSE}
iris$Sepal.Length[2] = "dog"
str(iris)
```

Note that all numeric values are changed to characters as well. You can try to force back the values to numeric by:

```{r chunk_chapter2_9, eval=FALSE}
iris$Sepal.Length = as.numeric(iris$Sepal.Length)
```

Have a look at what this does to the values in iris\$Sepal.Length.

Note: The actions above operate on a local copy of the iris data set. You don't overwrite the base data and can use it again in a new R session or reset it with `data(iris)`{.R}.

### Data Selection, Slicing and Subsetting

#### Subsetting and Slicing for Single Data Types

We often want to select only a subset of our data. You can generally subset from data structures using indices and TRUE/FALSE (or T/F). Here for a vector:

```{r chunk_chapter2_10, eval=FALSE, purl=FALSE}
vector = 1:6
vector[1] # First element.
vector[1:3] # Elements 1, 2, 3.
vector[c(1, 5, 6)]  # Elements 1, 5, 6.
vector[c(T, T, F, F, T)]  # Elements 1, 2, 5.
```

Careful, special behavior of R: If you specify fewer values than needed, the input vector will be repeated. This is called "recycling".

```{r chunk_chapter2_11, eval=FALSE, purl=FALSE}
vector[c(T, F)] # works but repeats T,F 3 times - error prone!
```

For a list, it's basically the same, except the following points:

-   Elements in lists usually have a name, so you can also access those via `list$name`{.R}.
-   Lists accessed with \[\] return a list. If you want to select a single element, you have to access it via \[\[\]\], as in `list[[2]]`{.R}.

```{r}
myList = list(a = 1, b = "dog", c = TRUE)
myList[1]
myList[[1]]
myList$a
```

For data.frames and other objects with dimension \> 2, the same is true, except that you have several indices.

```{r chunk_chapter2_12, eval=FALSE, purl=FALSE}
matrix = matrix(1:16, nrow = 4)
matrix[1, 2]  # Element in first row, second column.
matrix[1:2,]  # First two rows, all columns.
matrix[, c(T, F ,T)]  # All rows, 1st and 3rd column.
```

The syntax `matrix[1,]`{.R} is also called *slicing*, for obvious reasons.

Data.frames are the same as matrices, except that, like with lists of vectors, you can also access columns via names as in `data.frame$column`{.R}. This is because a data.frame ist a list of vectors.

#### Logic and Slicing

Slicing is very powerful if you combine it with logical operators, such as "&" (logical and), "\|" (logical or), "==" (equal), "!=" (not equal), "\<=", "\>", etc. Here are a few examples:

```{r chunk_chapter2_13}
head(iris[iris$Species == "virginica", ])  
```

Note that this is identical to using the subset command:

```{r chunk_chapter2_14}
head(subset(iris, Species == "virginica"))  
```

You can also combine several logical commands:

```{r chunk_chapter2_15}
iris[iris$Species == "virginica" & iris$Sepal.Length > 7, ]
```

### Applying Functions and Aggregates Across a Data Set

Apart from selecting data, you will often combine or calculate statistics on data.

#### Functions

Maybe this is a good time to remind you about functions. The two basic options we use in R are:

-   Variables / data structures.
-   Functions.

We have already used variables / data structures. Variables have a name and if you type this name in R, you get the values that are inside the respective data structure.

Functions are algorithms that are called like:

```{r chunk_chapter2_16, eval=FALSE, purl=FALSE}
function(variable)
```

For example, you can do:

```{r chunk_chapter2_17, eval=FALSE, purl=FALSE}
summary(iris)
```

If you want to know what the summary function does, type `?summary`{.R}, or put your mouse on the function and press "F1".

To be able to work properly with data, you have to know how to define your own functions. This works like the following:

```{r chunk_chapter2_18}
squareValue = function(x){
  temp = x * x 
  return(temp)
}
```

```{=html}
  <hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Tasks</span></strong><br/>
```
1.  Try what happens if you type in `squareValue(2)`{.R}.
2.  Write a function for multiplying 2 values. Hint: This should start with `function(x1, x2)`{.R}.
3.  Change the first line of the `squareValue`{.R} function to `function(x = 3)`{.R} and try out the following commands: `squareValue(2)`{.R}, `squareValue()`{.R}. What is the sense of this syntax?

```{=html}
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
```

***1***

```{r chunk_chapter2_task_0, eval=TRUE}
multiply = function(x1, x2){
  return(x1 * x2)
}
```

***2***

```{r chunk_chapter2_task_1, eval=TRUE}
squareValue(2)
```

***3***

```{r chunk_chapter2_task_2, eval=TRUE}
squareValue = function(x = 3){
  temp = x * x 
  return(temp)
}

squareValue(2)

squareValue()
```

The given value (3 in the example above) is the **default value**. This value is used automatically, if no value is supplied for the respective variable. Default values can be specified for all variables, but you should put them to the end of the function definition. Hint: In R, it is always useful to name the parameters when using functions.

Look at the following example:

```{r chunk_chapter2_task_3, eval=TRUE, error=TRUE, purl=FALSE}
testFunction = function(a = 1, b, c = 3){
  return(a * b + c)
}

testFunction()

testFunction(10)

testFunction(10, 20)

testFunction(10, 20, 30)

testFunction(b = 10, c = 20, a = 30)
```

```{=html}
    </p>
  </details>
  <br/><hr/>
```

#### The apply() Function

Now that we know functions, we can introduce functions that use functions. One of the most important is the apply function. The apply function applies a function of a data structure, typically a matrix or data.frame.

Try the following:

```{r chunk_chapter2_19, eval=FALSE}
apply(iris[,1:4], 2, mean)
```

```{=html}
  <hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Tasks</span></strong><br/>
```
1.  Check the help of `apply`{.R} to understand what this does.
2.  Why is the first result of `apply(iris[,1:4], 2, mean)`{.R} NA? Check the help of mean to understand this.
3.  Try `apply(iris[,1:4], 1, mean)`{.R}. Think about what has changed here.
4.  What would happen if you use `iris`{.R} instead of `iris[,1:4]`{.R}?

```{=html}
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
```
***1***

```{r chunk_chapter2_task_4, eval=FALSE}
?apply
```

***2***

Remember, what we have done above (if you run this part separately, execute the following lines again):

```{r chunk_chapter2_task_5, eval=TRUE, purl=FALSE}
iris$Sepal.Length[2] = "Hund"
iris$Sepal.Length = as.numeric(iris$Sepal.Length)
```

```{r chunk_chapter2_task_6, eval=TRUE}
apply(iris[,1:4], 2, mean)
```

Taking the mean of a character sequence is not possible, so the result is NA (**N**ot **A**vailable, missing value(s)).

But you can skip missing values with the option `na.rm = TRUE`{.R} of the `mean`{.R} function. To use it with the `apply`{.R} function, pass the argument(s) after.

```{r chunk_chapter2_task_7, eval=TRUE}
apply(iris[,1:4], 2, mean, na.rm = T)
```

***3***

```{r chunk_chapter2_task_8, eval=TRUE}
apply(iris[,1:4], 1, mean)
```

Arrays (and thus matrices, data.frame(s), etc.) have several dimensions. For a simple 2D array (or matrix), the first dimension is the rows and the second dimension is the columns. The second parameter of the "apply" function specifies the dimension of which the mean should be computed. If you use 1, you demand the row means (150), if you use 2, you request the column means (5, resp. 4).

***4***

```{r chunk_chapter2_task_9, eval=TRUE, purl=FALSE}
apply(iris, 2, mean)
```

The 5th column is "Species". These values are not numeric. So the whole data.frame is taken as a data.frame full of characters.

```{r chunk_chapter2_task_10, eval=TRUE}
apply(iris[,1:4], 2, str)
apply(iris, 2, str)
```

Remark: The "NULL" statement is the return value of apply. `str`{.R} returns nothing (but prints something out), so the returned vector (or array, list, ...) is empty, just like:

```{r chunk_chapter2_task_11, eval=TRUE}
c()
```

```{=html}
    </p>
  </details>
  <br/><hr/>
```

#### The aggregate() Function

`aggregate()`{.R} calculates a function per grouping variable. Try out this example:

```{r chunk_chapter2_20, eval=TRUE}
aggregate(. ~ Species, data = iris, FUN = max)
```

Note that `max`{.R}\` is the function to get the maximum value, and has nothing to do with your lecturer, who should be spelled Max.

The dot is general R syntax and usually refers to "use all columns in the data set".

#### For loops

Apply and aggregate are convenience function for a far more general concept that exists in all programming language, which is the for loop. In R, a for loop look like this:

```{r, eval = F}
for (i in 1:10){
  #doSomething
}
```

and if it is executed, it will excecute 10 times the main block in the curly brackes, while counting the index variable i from 1:10. To demonstrate this, let's execute a shorter for lool, going from 1:3, and printing i

```{r}
for (i in 1:3){
  print(i)
}
```

For loops are very useful when you want to execute the same task many times. This can be for plotting, but also for data manipulation. For example, if I would like to re-programm the apply function with a for loop, it would look like that:

```{r}
apply(iris[,1:4], 2, mean, na.rm = T)

out = rep(NA, 4)
for (i in 1:4){
  out[i] = mean(iris[,i])
}
out
```

### Plotting

I assume that you have already made plots with R. Else [here](https://www.youtube.com/embed/UXeJ1bNYCos) is a super-quick 5-min introduction video. In this course, we will not be using a lot graphics, but it will be useful for you to know the basic plot commands. Note in particular that the following two commands are identical:

-   `plot(iris$Sepal.Length, iris$Sepal.Width)`{.R}
-   `plot(Sepal.Width ~ Sepal.Length, data = iris)`{.R}

The second option is preferable, because it allows you to subset data easier and can be directly copied to regression functions.

```{r chunk_chapter2_21}
plot(Sepal.Width ~ Sepal.Length, data = iris[iris$Species == "versicolor", ])
```

The plot command will use the standard plot depending on the type of variable supplied. For example, if the x axis is a factor, a boxplot will be produced.

```{r chunk_chapter2_22}
plot(Sepal.Width ~ Species, data = iris)
```

You can change color, size, shape etc. and this is often useful for visualization.

```{r chunk_chapter2_23}
plot(iris$Sepal.Length, iris$Sepal.Width, col = iris$Species,
     cex = iris$Petal.Length)
```

For more help on plotting, I recommend:

-   Read ["Fundamentals of Data Visualization" by Claus O. Wilke](https://clauswilke.com/dataviz/) (explains all standard plots and why / when to use them)
-   [Data to Viz](https://www.data-to-viz.com) provides a decision tree for visualizations and links to the [R graph gallery](https://r-graph-gallery.com/index.html)



### Final exercise

::: {.callout-caution icon="false"}
#### Exercise - Data wrangling

We work with the airquality dataset:

```{r}
dat = airquality
```

1.  Before working with a dataset, you should always get an overview of it. Helpful functions for this are `str()`, `View()`, `summary()`, `head()`, and `tail()`. Apply them to `dat` and make sure to understand what they do.
2.  What is the data type of the variable 'Month'? Transform it to a factor
3.  Scale the variable Wind and save it as a new variable in `dat`
4.  Transform the variable 'Temp' (log-transform) and save it as a new variable in `dat`
5.  Extract the first 100 rows of `dat` and remove the NAs from the subsetted dataset
6.  Plot the variables of the dataset, and against each other (e.g. Wind, Wind vs Temp, Temp vs Month, all simultaneously)
7.  Calculate correlation indices between the numerical variables (e.g. Wind and Temp, Temp and Ozone). What is the difference between Spearman and Pearson correlation?
:::

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Solution

1.  `str()` helps us to check the data types of the variables, ensure that they are correct, e.g. categorical variables should be factors and continuous variables should be either num (numeric) or int (integer). `summary()`returns important summary statistics of our variables and informs us about NAs in the data

    ```{r}
    str(dat)
    summary(dat)
    ```

    There are NAs in Ozone and Solar.R! Also, Month is not a factor!

2.  We have to transform Month into a factor:

    ```{r}
    dat$Month = as.factor(dat$Month)
    str(dat)
    ```

3.  Scaling means that the variables are centered and standardized (divided by their standard deviation):

    ```{r}
    dat$sWind = scale(dat$Wind)
    summary(dat)
    ```

4.  Use `log`function to transform the variable (be aware of NAs!)

    ```{r}
    dat$logTemp = log(dat$Temp)
    ```

5.  Use `[rows, cols]` to subset the data and `complete.cases()` to remove observations with NAs

    ```{r}
    dat_sub = dat[1:100,]
    summary(dat_sub)
    dat_sub = dat_sub[complete.cases(dat_sub),]
    summary(dat_sub)
    ```

6.  Single continuous variables can be visualized using a histogram (`hist)` , for two variables, it depends on their data types:

    | Scenario | Which plot | R command |
    |----------------|----------------|---------------------------------------|
    | Numeric | Histogram or boxplot | `hist()` and`boxplot` |
    | Numeric with numeric | Scatterplot | `plot` |
    | Numeric with categorical | Boxplot | `boxplot(numeric~categorical)` |
    | Categorical with categorical | mosaicplot or grouped barplot | `mosaicplot(table(categorical, categorical))` or `barplot(data,        beside=TRUE)` |

    ```{r}
    # Numeric
    hist(dat$Wind, main = "Wind")

    # Numeric vs numeric
    plot(dat$Wind, dat$Solar.R)

    # Numeric with categorical
    boxplot(Wind~Month, data = dat)

    # All with all
    pairs(dat)
    ```

7.  Spearman is a rank correlation factor, less sensitive against outliers and non-linearity:

    ```{r}
    # Pearson
    cor(dat$Wind, dat$Temp, use = "complete.obs")

    # Spearman
    cor(dat$Wind, dat$Temp, use = "complete.obs", method = "spearman")
    ```
:::
