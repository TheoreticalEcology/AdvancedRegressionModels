---
output: html_document
editor_options: 
  chunk_output_type: console
---
```{r, include=FALSE}
set.seed(42)
```

# Case studies

General strategy for analysis:

1.  Define formula via scientific questions + confounders.
2.  Define type of GLM (lm, logistic, Poisson).
3.  Blocks in data -\> Random effects, start with random intercept.

Fit this base model, then do residual checks for

-   Wrong functional form -\> Change fitted function.
-   Wrong distribution-\> Transformation or GLM adjustment.
-   (Over)dispersion -\> Variable dispersion GLM.
-   Heteroskedasticity -\> Model dispersion.
-   Zero-inflation -\> Add ZIP term.
-   ...

And adjust the model accordingly.

## Hurricanes

In <a href="https://www.pnas.org/content/111/24/8782" target="_blank" rel="noopener">https://www.pnas.org/content/111/24/8782</a>, Jung et al. claim that "Female hurricanes are deadlier than male hurricanes".

Specifically, they analyze the number of hurricane fatalities, and claim that there is an effect of the femininity of the name on the number of fatalities, correcting for several possible confounders. They interpret the result as causal (including mediators), claiming that giving only male names to hurricanes would considerably reduce death toll.

The data is available in `DHARMa`{.R}.

```{r chunk_chapter5_task_5, eval=TRUE, message=FALSE, warning=FALSE}
library(DHARMa)
library(mgcv)
?hurricanes
str(hurricanes)
```

Some plots:

```{r chunk_chapter5_task_6, eval=TRUE, message=FALSE, warning=FALSE}
plot(hurricanes$MasFem, hurricanes$NDAM, cex = 0.5, pch = 5)
points(hurricanes$MasFem, hurricanes$NDAM, cex = hurricanes$alldeaths/20,
       pch = 4, col= "red")
```

The original model from the paper fits a negative binomial, using `mgcv`.{R}. I suppose the reason is mainly that glmmTMB was not available at the time, and implementations of the negative binomial, in particular mass::glm.nb and lme4::glmer.nb often had convergence problems. 

```{r chunk_chapter5_task_7, eval=TRUE, message=FALSE, warning=FALSE}
originalModelGAM = gam(alldeaths ~ MasFem * (Minpressure_Updated_2014 + NDAM),
    data = hurricanes, family = nb, na.action = "na.fail")
summary(originalModelGAM)
```

::: {.callout-caution icon="false"}
Tasks:

-   Confirm that you get the same results as in the paper. It makes sense to translate their model to glmmTMB. Note that the nb parameterization of mgcv corresponds to nbinom2 in glmmTMB. You will get different results when choosing nbinom1 
-   Inspect the fitted model for potential problems, in particular perform a residual analysis of the model, including residuals against all predictors, and improve the model if you find problems.
-   Forget what they did. Go back to start, do a causal analysis like we did, and do your own model, diagnosing all residual problems that we discussed. Do you think there is an effect of femininity?
:::

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Solution

This is the model fit by Jung et al., fit with glmmTMB

```{r}
library(DHARMa)
library(glmmTMB)

m1 = glmmTMB(alldeaths ~ MasFem*
                             (Minpressure_Updated_2014 + scale(NDAM)),
                           data = hurricanes, family = nbinom2)
summary(m1)
```

Note that in the code that I gave you not all predictors were scaled (and they don't say if they scaled in the paper), but as we for looking for main effects in the presence of interactions, we should definitely scale to improve the interpretability

```{r}
m2 = glmmTMB(alldeaths ~ scale(MasFem) *
                             (scale(Minpressure_Updated_2014) + scale(NDAM)),
                           data = hurricanes, family = nbinom2)
summary(m2)
```

now main effect is n.s.; it's a bit dodgy, but if you read in the main paper, they do not claim a significant main effect, they mainly argue via ANOVA and significance at high values of NDAM, so let's run an ANOVA:

```{r}
car::Anova(m2)
```

In the ANOVA we see that MasFem still n.s. but interactions, and if you would calculate effect of MasFem at high NDAM, it is significant. Something like that is argued in the paper. We can emulate this by changing NDAM centering to high NDAM, which gives us a p-value for the main effect of MasFem at high values of NDAM

```{r}
hurricanes$highcenteredNDAM = hurricanes$NDAM - max(hurricanes$NDAM)

m3 = glmmTMB(alldeaths ~ scale(MasFem) *
                             (scale(Minpressure_Updated_2014) + highcenteredNDAM),
                           data = hurricanes, family = nbinom2)
summary(m3)
```

Now we see the significant main effect that they report. Note, hwoever, that the signficant differences is only there for high NDAM, i.e. what we do here is to project the effect of the interaction on the main effect. An alternative to do the same thing would be an effects plot, or to specifically use predict() to calculate differences and CIs at high NDAM values. 

```{r}
library(effects)
plot(allEffects(m3, partial.residuals = T))
```

OK, this means we can replicate the results of the paper, even if concentrating the entire analysis exclusive on high NDAM seems a bit cherry-picking. Another way to phrase the result is that we don't find a main effect of MasFem. However, to be fair: the current results to say that there is a significant difference at high NDAM, and such a difference, if it existed, would be importat. 

But we haven't done residual checks yet. Let's do that: 

```{r}
res <- simulateResiduals(originalModelGAM)
plot(res)

plotResiduals(res, hurricanes$NDAM)
plotResiduals(res, hurricanes$MasFem)
plotResiduals(res, hurricanes$Minpressure_Updated_2014)
```

No significant deviation in the general DHARMa plot, but residuals ~ NDAM looks funny, which was also pointed out by Bob O'Hara in a blog post after publication of the paper. Let's try to correct this - scaling with ^0.2 does a great job:

```{r}
correctedModel = glmmTMB(alldeaths ~ scale(MasFem) *
                             (scale(Minpressure_Updated_2014) + scale(NDAM^0.2)),
                          data = hurricanes, family = nbinom2)

res <- simulateResiduals(correctedModel, plot = T)
plotResiduals(res, hurricanes$NDAM)
summary(correctedModel)
car::Anova(correctedModel)

```

All gone, only damage is doing the effect. This wouldn't change with re-scaling probably, as interactions are n.s.

What if we would have fit our own model? First of all, note that if hurricane names were given randomly, we wouldn't have to worry about confounders. However, this is not the case, hurricanes were only named randomly after 1978 or so. 

```{r}
plot(MasFem ~ Year, data = "hurricanes")
```

So, we could either take the earlier data out, which would remove half of our data, or we have to worry about confounding with variables that change over time. The most obvious thing would be to take time itself (Year) in the model, to correct for temporal confounding. 

Do we need other variables that are not confounders? There is two reasons to add them:

* they have strong effects on the response - not adding them could lead to residual problems and increase residual variance, which increases uncertainties and cost power
* we want to fit interacts.

I added NDAM to the model, because we saw earlier that it has a strong effect. I think it's not unreasonable to check for an interaction as well. 

As we have several observations per year, a conservative approach would be to add a RE on year. Note that we use year both as a fixed effect (to remove temporal trends) and a random intercept, which is perfectly fine, however. 

```{r}
newModel = glmmTMB(alldeaths ~ scale(MasFem) * scale(NDAM^0.2) + Year + (1|Year),
                           data = hurricanes, family = nbinom2)
summary(newModel)

car::Anova(newModel) # nothing regarding MasFem
```

The results remain that there is no effect of MasFem!

:::

## Researchers Degrees of Freedom --- Skin Color and Red Cards

In 2018 Silberzahn et al. published a "meta analysis" in *Advances in Methods and Practices in Psychological Science*, where they had provided 29 teams with the same data set to answer one research question: "*\[W\]hether soccer players with dark skin tone are more likely than those with light skin tone to receive red cards from referees*".

**Spoiler**: They found that the "\[a\]nalytic approaches varied widely across the teams, and the estimated effect sizes ranged from 0.89 to 2.93 (Mdn = 1.31) in odds-ratio units", highlighting that different approaches in data analysis can yield significant variation in the results.

You can find the paper "Many Analysts, One Data Set: Making Transparent How Variations in Analytic Choices Affect Results" at: <a href="https://journals.sagepub.com/doi/10.1177/2515245917747646" target="_blank" rel="noopener">https://journals.sagepub.com/doi/10.1177/2515245917747646</a>.

Task: Do a re-analysis of the data as if you were the 30th team to contribute the results to the meta analysis. You can find the data in the ecodata package, dataset redCards.

1.  Response variable: 'redCards' (+'yellowReds'?).
2.  primary predictors: 'rater1', 'rater2'
3.  Multiple variables, potentially accounting for confounding, offsetting, grouping, ... are included in the data.

The rater variable contains ratings of "two independent raters blind to the research question who, based on their profile photo, categorized players on a 5-point scale ranging from (1) very light skin to (5) very dark skin. Make sure that 'rater1' and 'rater2' are rescaled to the range 0 ... 1 as described in the paper ("This variable was rescaled to be bounded by 0 (very light skin) and 1 (very dark skin) prior to the final analysis, to ensure consistency of effect sizes across the teams of analysts. The raw ratings were rescaled to 0, .25, .50, .75, and 1 to create this new scale.")

When you're done, have a look at the other modelling teams. Do you understand the models they fit? Note that the results are displayed in terms of **odd ratios**. Are your results within the range of estimates from the 29 teams in Silberzahn et al. (2018)?

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Solution



:::

## Scouting Ants

Look at the dataset EcoData::scoutingAnts, and find out if there are really scouting Ants in Lasius Niger.

A base model should be:

```{r}
# select all data for the second visit
dat = scoutingAnts[scoutingAnts$first.visit == 0,]
dat$ant_group = as.factor(dat$ant_group)
dat$ant_group_main = as.factor(dat$ant_group_main)

fit <- glm(went.phero ~ ant_group_main, data = dat)
summary(fit)
```


::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Solution


For me, it made sense to change the contrasts of the possible confounders into something more easily interpretable: 

* Did the side in which the pheromone was stay constant or not (testing for a directional persistence of the ants)

* Was the pheromone in the left or the right arm (testing for a directional preference)


```{r}
dat$directionConst = ifelse(dat$Treatment %in% c("LL", "RR"), T, F)
dat$directionPhero = as.factor(ifelse(dat$Treatment %in% c("LL", "RL"), "left", "right"))
```

Together with the orientation of the Maze, this makes 3 possible directional confounders, and the main predictor (if the Ant went to the pheromone in the first visit). 

Adding an RE on colony is logical, and then let's run the model: 

```{r}
fit1<-glmer(went.phero ~ ant_group_main
             + directionConst
             + directionPhero
             + Orientation
             + (1|Colony),family="binomial", 
             data=dat)
summary(fit1)
```

Surprisingly, we find large effects of the other variables. Because of these large effects, testing for interactions with the experimental treatment as well

```{r}
fit2<-glmer(went.phero ~ ant_group_main * (
             + directionConst
             + directionPhero
             + Orientation)
             + (1|Colony),family="binomial", 
             data=dat)
summary(fit2)
```

Here we find now that ther is an interaction with the main predictor, and there could be effects. We can also look at this visually. 

```{r}
plot(allEffects(fit2))
```

The results are difficult to interpret. I would think that there was some bias in the experiment, which led to an effect of the Maze direction, which then create a spill-over to the other (and in particular the main) predictors. 

For our education, we can also look at the residual plots. I will use m1, because there was a misfit:


```{r}
res <- simulateResiduals(m1, plot = T)
```

As we would significant interactions, we would probably see something 



:::

## Owls

Look at the Owl data set in the `glmmTMB` package. The initial hypothesis is

```{r chunk_chapter5_task_3, message=FALSE, warning=FALSE}
library(glmmTMB)

m1 = glm(SiblingNegotiation ~ FoodTreatment*SexParent + offset(log(BroodSize)),
         data = Owls , family = poisson)
res = simulateResiduals(m1)
plot(res)
```

::: {.callout-caution icon="false"}
#### Offset

The offset is a special command that can be used in all regression models. It means that we include an effect with effect size 1.

The offset has a special importance in models with a log link function, because with these models, we have y = exp(x ...), so if you do y = exp(x + log(BroodSize) ) and use exp rules, this is y = exp(x) \* exp(log(BroodSize)) = y = exp(x) \* BroodSize, so this makes the response proportional to BroodSize. This trick is often used in log link GLMs to make the response proportional to Area, Sampling effort, etc.
:::

*Task:* try to improve the model with everything we have discussed so far.

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Solution

```{r chunk_chapter5_task_4, message=FALSE, warning=FALSE}
m1 = glmmTMB::glmmTMB(SiblingNegotiation ~ FoodTreatment * SexParent
  + (1|Nest) + offset(log(BroodSize)), data = Owls , family = nbinom1,
  dispformula = ~ FoodTreatment + SexParent,
  ziformula = ~ FoodTreatment + SexParent)
summary(m1)

res = simulateResiduals(m1, plot = T)

testDispersion(m1)
testZeroInflation(m1)
```
:::

## Snails

```{r, warning=FALSE, message=FALSE}
library(EcoData)
library(glmmTMB)
library(lme4)
library(DHARMa)
library(tidyverse)
?EcoData::snails
```

Look at the Snails data set in the `EcoData` package, and find out which environmental and/or seasonal predictors i) explain the total abundance and ii) the infection rate of the three species.

The snails data set in the EcoData package includes observations on the distribution of freshwater snails and their infection rates ( schistosomiasis (a parasit)).

The first scientific question is that their adbundance depends on the water conditions. The second scientific question is that their infection rate depends on the water conditions and seasonsal factors

The data also contains data on other environmental (and seasonal factors). You should consider if it is useful to add them to the analysis.

Species: BP_tot, BF_tot, BT_tot

Number of infected individuals: BP_pos_tot, BF_pos_tot, BT_pos_tot

Total abundances of BP species: Bulinus_tot

Total number of infected in BP species: Bulinus_pos_tot

Tasks:

1.  Model the summed total abundance of the three species (Bulinus_tot)

2.  Model the infection rate of all three species (Bulinuts_pos_tot) (k/n binomial)

3.  Optional: Model the species individually (BP_tot, BF_tot, BT_tot)

4.  Optional: Fit a multivariate (joint) species distribution model

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Solution for total Abundance of *Bulinus* (glmm)

Prepare+scale data:

```{r}
library(lme4)
library(glmmTMB)
library(DHARMa)
data = EcoData::snails
data$sTemp_Water = scale(data$Temp_Water)
data$spH = scale(data$pH)
data$swater_speed_ms = scale(data$water_speed_ms)
data$swater_depth = scale(data$water_depth)
data$sCond = scale(data$Cond)
data$swmo_prec = scale(data$wmo_prec)
data$syear = scale(data$year)
data$sLat = scale(data$Latitude)
data$sLon = scale(data$Longitude)
data$sTemp_Air = scale(data$Temp_Air)

# Let's remove NAs beforehand:
rows = rownames(model.matrix(Bulinus_tot~sTemp_Water + spH + sLat + sLon + sCond + seas_wmo+ swmo_prec + swater_speed_ms + swater_depth +sTemp_Air+ syear + duration + locality + site_irn + coll_date, data = data))
data = data[rows, ]

```

Our hypothesis is that the abundance of Bulinus species depends on the water characteristics, e.g. site_type, Temp_water, pH, Cond, swmo_prec, water_speed_ms, and water_depth. We will set the length of the collection duration as an offset.

```{r}
model1 = glm(Bulinus_tot~
                 offset(log(duration)) + site_type + sTemp_Water + spH +
                 sCond + swmo_prec + swater_speed_ms + swater_depth,
              data = data,  family = poisson)
summary(model1)
```

As the sites are nested within localities, we will set a nested random intercept on site_irn within locality. Also potential confounders can be collection date (coll_date), the season (wet or dry months, seas_wmo), year, and maybe other environmental factors such as the air temperature?.

```{r}
model2 = glmer(Bulinus_tot~
                 offset(log(duration)) + site_type + sTemp_Water + spH +
                 sCond + swmo_prec + swater_speed_ms + swater_depth +
                 sTemp_Air + seas_wmo + (1|year) + (1|locality/site_irn) +  (swater_depth|coll_date),
              data = data,  family = poisson)
summary(model2)
```

Check residuals:

```{r}
res = simulateResiduals(model2, plot = TRUE, re.form = NULL)
```

Does not look great -\> dispersion problems -\> switch to -\> negative binomial distribution:

```{r}

model3 = glmmTMB(Bulinus_tot~
                 offset(log(duration)) + site_type + sTemp_Water + spH +
                 sCond + swmo_prec + swater_speed_ms + swater_depth +
                 sTemp_Air + seas_wmo + (1|year) + (1|locality/site_irn) +  (swater_depth|coll_date),
              data = data,  family = nbinom2)
summary(model3)
```

Check residuals:

```{r}
res = simulateResiduals(model3, plot = TRUE)
```

Residuals look better but there is still a dispersion problem.

Let's use the dispformula:

```{r}
model4 = glmmTMB(Bulinus_tot~
                 offset(log(duration)) + site_type + sTemp_Water + spH +
                 sCond + swmo_prec + swater_speed_ms + swater_depth +
                 sTemp_Air + seas_wmo + (1|year) + (1|locality/site_irn) +  (swater_depth|coll_date),
                 dispformula = ~swater_speed_ms + swater_depth+sCond,
              data = data,  family = nbinom2)
summary(model4)
```

Dispformula is significant. Residuals:

```{r}
res = simulateResiduals(model4, plot = TRUE)
```

Dispersion tests are n.s.:

```{r}
testDispersion(res)
testZeroInflation(res)
```

We detrended space there could be spatial autocorrelation, let's check for it:

```{r}
## Spatial
res2 = recalculateResiduals(res, group = c(data$site_irn))
groupLocations = aggregate(cbind(data$sLat, data$sLon ), list( data$site_irn), mean)
testSpatialAutocorrelation(res2, x = groupLocations$V1, y = groupLocations$V2)

```

Significant! Let's add a spatial correlation structure:

```{r}
numFac = numFactor(data$sLat, data$sLon)
group = factor(rep(1, nrow(data)))
data$fmonth = as.factor(data$month)

model5 = glmmTMB(Bulinus_tot~
                 offset(log(duration)) + site_type + sTemp_Water + spH +
                 sCond + swmo_prec + swater_speed_ms + swater_depth +
                 sTemp_Air + seas_wmo + (1|year) + (1|locality/site_irn) +  (swater_depth|coll_date) + exp(0+numFac|group),
                 dispformula = ~swater_speed_ms + swater_depth+sCond,
              data = data,  family = nbinom2)
```

```{r}
res = simulateResiduals(model5, plot = TRUE)
```

glmmTMB does not support conditional simulations but we can create conditional simulations on our own:

```{r}
pred = predict(model5, re.form = NULL, type = "response")
pred_dispersion = predict(model5, re.form = NULL, type = "disp")
simulations = sapply(1:1000, function(i) rnbinom(length(pred),size = pred_dispersion, mu =  pred))
res = createDHARMa(simulations, model.frame(model4)[,1], pred)
plot(res)
```

Residuals do not look perfect but I would say that we can stop here now.
:::

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Solution for prevalence of *Bulinus* (glmm)

Prepare+scale data:

```{r}
library(lme4)
library(glmmTMB)
library(DHARMa)
data = EcoData::snails
data$sTemp_Water = scale(data$Temp_Water)
data$spH = scale(data$pH)
data$swater_speed_ms = scale(data$water_speed_ms)
data$swater_depth = scale(data$water_depth)
data$sCond = scale(data$Cond)
data$swmo_prec = scale(data$wmo_prec)
data$syear = scale(data$year)
data$sLat = scale(data$Latitude)
data$sLon = scale(data$Longitude)
data$sTemp_Air = scale(data$Temp_Air)

# Let's remove NAs beforehand:
rows = rownames(model.matrix(Bulinus_tot~sTemp_Water + spH + sLat + sLon + sCond + seas_wmo+ swmo_prec + swater_speed_ms + swater_depth +sTemp_Air+ syear + duration + locality + site_irn + coll_date, data = data))
data = data[rows, ]

```

Let's start directly with all potential confounders (see previous solution):

```{r}
model1 = glmmTMB(cbind(Bulinus_pos_tot, Bulinus_tot - Bulinus_pos_tot )~
                 offset(log(duration)) + site_type + sTemp_Water + spH +
                 sCond + swmo_prec + swater_speed_ms + swater_depth +
                 sTemp_Air + seas_wmo + (1|year) + (1|locality/site_irn) +  (swater_depth|coll_date)
              data = data,  family = binomial)
summary(model1)

```

```{r}
res = simulateResiduals(model1, plot=TRUE)
```

We have dispersion problems, but we cannot model the dispersion for binomial models.

Check for spatial autocorrelation:

```{r}
## Spatial
res2 = recalculateResiduals(res, group = c(data$site_irn))
groupLocations = aggregate(cbind(data$sLat, data$sLon ), list( data$site_irn), mean)
testSpatialAutocorrelation(res2, x = groupLocations$V1, y = groupLocations$V2)

```

Significant! Let's correct for spatial autocorrelation with a correlation structure:

```{r}
numFac = numFactor(data$sLat, data$sLon)
group = factor(rep(1, nrow(data)))
data$fmonth = as.factor(data$month)
model2 = glmmTMB(cbind(Bulinus_pos_tot, Bulinus_tot - Bulinus_pos_tot )~
                 offset(log(duration)) + site_type + sTemp_Water + spH +
                 sCond + swmo_prec + swater_speed_ms + swater_depth +
                 sTemp_Air + seas_wmo + (1|year) + (1|locality/site_irn) +  (swater_depth|coll_date) + exp(0+numFac|group),
              data = data,  family = binomial)
```

```{r}
res = simulateResiduals(model2, plot = TRUE)
```

They look good now!
:::

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Solution of multivariate (joint) species distribution model

The species models are connected by their response to latent variable (unobserved environment). For that, we will transform our dataset with respect to species from wide (sp1, sp2, sp3) to long format (species abundances in one column and a second column telling us the group (species)). In the model then, we will separate the species and their responses by using \~0+Species + Species:(predictors).

The latent variable structure is set by the `rr(â€¦)` object in the formula:

```{r}
library(lme4)
library(glmmTMB)
library(DHARMa)
library(tidyverse)
data = EcoData::snails
data$sTemp_Water = scale(data$Temp_Water)
data$spH = scale(data$pH)
data$swater_speed_ms = scale(data$water_speed_ms)
data$swater_depth = scale(data$water_depth)
data$sCond = scale(data$Cond)
data$swmo_prec = scale(data$wmo_prec)
data$syear = scale(data$year)
data$sLat = scale(data$Latitude)
data$sLon = scale(data$Longitude)
data$sTemp_Air = scale(data$Temp_Air)

# Let's remove NAs beforehand:
rows = rownames(model.matrix(cbind(Bulinus_pos_tot, Bulinus_tot-Bulinus_pos_tot)~sTemp_Water + spH + sLat + sLon + sCond + seas_wmo+ swmo_prec + swater_speed_ms + swater_depth +sTemp_Air+ syear + duration + locality + site_irn + coll_date, data = data))
data = data[rows, ]


data =
  data %>% pivot_longer(cols = c("BP_tot", "BF_tot", "BT_tot"),
                      names_to = "Species",
                      values_to = "Abundance" )

numFac = numFactor(data$sLat, data$sLon)
group = factor(rep(1, nrow(data)))

numFac = numFactor(data$sLat, data$sLon)
group = factor(rep(1, nrow(data)))
data$fmonth = as.factor(data$month)
modelJoint = glmmTMB(Abundance~ 0 +
                 offset(log(duration)) + Species + Species:(site_type + 
                  sTemp_Water + spH + sCond + swmo_prec + swater_speed_ms + swater_depth +
                 sTemp_Air + seas_wmo) + (1|year) + (1|locality/site_irn) +  (swater_depth|coll_date:Species) + exp(0+numFac|group) + rr(Species + 0|locality:site_irn, d = 2),
                 dispformula = ~0+Species+Species:(swater_speed_ms + swater_depth+sCond),
              data = data,  family = nbinom2)



```

Unconditional residuals:

```{r}
plot(simulateResiduals(modelJoint))
```

Conditional residuals:

```{r}
pred = predict(modelJoint, re.form = NULL, type = "response")
pred_dispersion = predict(modelJoint, re.form = NULL, type = "disp")
simulations = sapply(1:1000, function(i) rnbinom(length(pred),size = pred_dispersion, mu =  pred))
res = createDHARMa(simulations, model.frame(modelJoint)[,1], pred)
plot(res)
```


:::

## Seed bank

```{r, warning=FALSE,message=FALSE}
library(EcoData)
library(glmmTMB)
library(lme4)
library(lmerTest)
library(DHARMa)
library(tidyverse)
?EcoData::seedBank
```

The seedBank data set in the EcoData package includes observation on seed bank presence and size in different vegetaition plots.

The scientific question is if the ability of plants to build a seed bank depends on their seed traits (see help).

The data also contains data on environmental factors and plant traits. You should consider if it is useful to add them to the analysis.

Tasks:

1.  Fit a lm/lmm with SBDensity as response

2.  Bonus: Add phylogenetic correlation structure

3.  Fit a glm/glmm with SBPA as response (Bonus: add phylogenetic correlation structure)

::: {.callout-caution icon="false"}
#### Solution for SBDensity (lmm)

Prepare+scale data:

```{r}
data = as.data.frame(EcoData::seedBank)
data$sAltitude = scale(data$Altitude)
data$sSeedMass = scale(data$SeedMass)
data$sSeedShape = scale(data$SeedShape)
data$sSeedN = scale(data$SeedN)
data$sSeedPr = scale(data$SeedPr)
data$sDormRank = scale(data$DormRank)
data$sTemp = scale(data$Temp)
data$sHum = scale(data$Humidity)
data$sNitro = scale(data$Nitrogen)
data$sGrazing = scale(data$Grazing)
data$sMGT = scale(data$MGT)
data$sJwidth = scale(data$Jwidth)
data$sEpiStein = scale(data$EpiStein)
data$sMGR = scale(data$MGR)
data$sT95 = scale(data$T95)

# Let's remove NAs beforehand:
rows = rownames(model.matrix(SBDensity~sAltitude + sSeedMass + sSeedShape + sSeedN +
                               sSeedPr + sDormRank + sTemp + sHum + sNitro + sMGT + 
                               sMGR + sEpiStein + sT95 +
                               sJwidth + sGrazing + Site + Species, data = data))
data = data[rows, ]
```

The response is highly skewed, so it makes sense to log-transform:

```{r}
hist(data$SBDensity)
data$logSBDensity = log(data$SBDensity + 1)
```

Let's fit a base model with with our hypothesis that logSBDensity \~ sSeedMass (Seed Mass) + sSeedShape + sSeedN (Number of Seeds).

We set random intercepts on species and sites because we assume that there are species and site specific variations:

```{r}

model1 = lmer(logSBDensity~
                sSeedMass + sSeedShape + sSeedN + 
                (1|Site) + (1|Species),
              data = data)

summary(model1)
```

Environmental factors can be potential confounders, let's add them to the model:

```{r}

model2 = lmer(logSBDensity~
                sSeedMass + sSeedShape + sSeedN +
                 sAltitude + sHum + 
                (1|Site) + (1|Species),
              data = data)

summary(model2)
```

sSeedShape and sSeedN are now statistically significant!

**Question**:

What about the germination temperatures, T50/T95?

**Answer:**

They could be mediators, Seed Shape -\> T95 -\> SBDensity, so it is up to if you want to include them or not!

**Residual checks:**

Check for missing random slopes:

```{r, fig.width=10, fig.height=15}
plot(model2, resid(., rescale=TRUE) ~ fitted(.) | Species, abline = 1)
```

There seems to be a pattern!

```{r, fig.width=10, fig.height=15}
plot(model2, resid(., rescale=TRUE) ~ sAltitude | Species, abline = 1)
```

The pattern seems to be caused by sAltitude (check `plot(model2, resid(., rescale=TRUE) ~ sSeedMass | Species, abline = 1)` )

**Random slope model**

Let's add a random slope on sAlitude:

```{r}

model3 = lmer(logSBDensity~
                sSeedMass + sSeedShape + sSeedN +
                sAltitude + sHum + 
                (1|Site) + (sAltitude|Species),
              data = data)

summary(model3)
```

**Residual checks:**

```{r}
plot(simulateResiduals(model3, re.form=NULL))
```

There seems to be dispersion problem.

**Bonus: Modeling variance with glmmTMB**

```{r}
model4 = glmmTMB(logSBDensity~
                sSeedMass + sSeedShape + sSeedN +
                sAltitude + sHum + 
                (1|Site) + (sAltitude|Species),
              dispformula = ~sAltitude + sHum,
              data = data)
summary(model4)
```
:::

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Bonus: Solution for SBDensity (lmm) with phylogenetic correlation structure

Prepare phylogeny:

```{r}
library(ape)
library(geiger)
species = unique(data$Species)
species_df = data.frame(Species = species)
rownames(species_df) = species
obj = name.check(plantPhylo, species_df)

# drop rest of the species
phyl.upd = drop.tip(plantPhylo, obj$tree_not_data)
summary(phyl.upd)

# check the names in the tree and in the data set
name.check(phyl.upd, species_df)

phyl.upd2 = multi2di(phyl.upd)
```

nlme:

```{r}
library(nlme)
model4 = gls(logSBDensity ~
              sSeedMass + sSeedShape + sSeedN +
                 sAltitude + sHum,
             correlation = corBrownian(phy = phyl.upd2, form =~ Species),
             data = data)
summary(model4)

```

glmmTMB (not perfect because lack of support of specific phylogenetic correlation structures):

```{r}
dist_phylo = ape::cophenetic.phylo(phyl.upd2) # create distance matrix
correlation_matrix = vcv(phyl.upd2)[unique(data$Species), unique(data$Species)]

###
#the following code was taken from https://github.com/glmmTMB/glmmTMB/blob/master/misc/fixcorr.rmd
as.theta.vcov <- function(Sigma,corrs.only=FALSE) {
    logsd <- log(diag(Sigma))/2
    cr <- cov2cor(Sigma)
    cc <- chol(cr)
    cc <- cc %*% diag(1 / diag(cc))
    corrs <- cc[upper.tri(cc)]
    if (corrs.only) return(corrs)
    ret <- c(logsd,corrs)
    return(ret)
}
corrs = as.theta.vcov(correlation_matrix, corrs.only=TRUE)
#####

data$dummy = factor(rep(0, nrow(data)))
nsp = length(unique(data$Species))
model5 = glmmTMB(logSBDensity~
                sSeedMass + sSeedShape + sSeedN + 
                sAltitude + sHum +
                (1|Site) + (sAltitude|Species) +
                (1+Species|dummy),
              dispformula = ~sAltitude + sHum,
              map=list(theta=factor(c(rep(0, 4), rep(1,nsp),rep(NA,length(corrs))) )),
              start=list(theta=c(rep(0, 4), rep(0,nsp),corrs)),
              data = data)
summary(model5)
simulateResiduals(model5, plot = TRUE) # Unconditional simulations
```
:::

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Solution for SBPA (glmm)

Prepare+scale data:

```{r}
data = as.data.frame(EcoData::seedBank)
data$sAltitude = scale(data$Altitude)
data$sSeedMass = scale(data$SeedMass)
data$sSeedShape = scale(data$SeedShape)
data$sSeedN = scale(data$SeedN)
data$sSeedPr = scale(data$SeedPr)
data$sDormRank = scale(data$DormRank)
data$sTemp = scale(data$Temp)
data$sHum = scale(data$Humidity)
data$sNitro = scale(data$Nitrogen)
data$sGrazing = scale(data$Grazing)
data$sMGT = scale(data$MGT)
data$sJwidth = scale(data$Jwidth)
data$sEpiStein = scale(data$EpiStein)
data$sMGR = scale(data$MGR)
data$sT95 = scale(data$T95)

# Let's remove NAs beforehand:
rows = rownames(model.matrix(SBDensity~sAltitude + sSeedMass + sSeedShape + sSeedN +
                               sSeedPr + sDormRank + sTemp + sHum + sNitro + sMGT + 
                               sMGR + sEpiStein + sT95 +
                               sJwidth + sGrazing + Site + Species, data = data))
data = data[rows, ]

```

```{r}

model1 = glmer(SBPA~
                sSeedMass + sSeedShape + sSeedN + 
                 sAltitude + sHum +
                (1|Site) + (sAltitude|Species),
              data = data, family = binomial())
summary(model1)
```

Model did not converge, but there is a trick which often helps. The default optimizer in lme4 is not the best optimizer, changing it to 'bobyqa' often helps with convergence issues

```{r}
model1 = glmer(SBPA~
                sSeedMass + sSeedShape + sSeedN + 
                sAltitude + sHum +
                (1|Site) + (sAltitude|Species),
              data = data, family = binomial(),
              control = glmerControl('bobyqa'))
summary(model1)
```

Success, it converged!

**Residual checks:**

Check residuals:

```{r}
res = simulateResiduals(model1, re.form=NULL, plot=TRUE)
```

Residuals look good!

**Bonus: With phylogenetic correlation structure:**

```{r}
dist_phylo = ape::cophenetic.phylo(phyl.upd2) # create distance matrix
correlation_matrix = vcv(phyl.upd2)[unique(data$Species), unique(data$Species)]

###
#the following code was taken from https://github.com/glmmTMB/glmmTMB/blob/master/misc/fixcorr.rmd
as.theta.vcov <- function(Sigma,corrs.only=FALSE) {
    logsd <- log(diag(Sigma))/2
    cr <- cov2cor(Sigma)
    cc <- chol(cr)
    cc <- cc %*% diag(1 / diag(cc))
    corrs <- cc[upper.tri(cc)]
    if (corrs.only) return(corrs)
    ret <- c(logsd,corrs)
    return(ret)
}
corrs = as.theta.vcov(correlation_matrix, corrs.only=TRUE)
#####

data$dummy = factor(rep(0, nrow(data)))
nsp = length(unique(data$Species))
model6 = glmmTMB(SBPA~
                sSeedMass + sSeedShape + sSeedN + 
                sAltitude + sHum +
                (1|Site) + (sAltitude|Species) +
                (1+Species|dummy),
              map=list(theta=factor(c(rep(0, 4), rep(1,nsp),rep(NA,length(corrs))) )),
              start=list(theta=c(rep(0, 4), rep(0,nsp),corrs)),
              family = binomial,
              data = data)
simulateResiduals(model6, plot = TRUE)
```

Conditional simulations:

```{r}
pred = predict(model6, re.form = NULL, type = "response")
simulations = sapply(1:1000, function(i) rbinom(length(pred),1, pred))
res = createDHARMa(simulations, model.frame(model6)[,1], pred)
plot(res)
```
:::

## Snouter

Fit one of the responses in the snouter datset against the predictors rain + djungle (see ?snouter). Check for spatial autocorrelation and proceed to fitting a spatial model if needed. See the data set's help for details on the variables.

```{r eval = F}
library(EcoData)
str(snouter)
```

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Solution
:::
