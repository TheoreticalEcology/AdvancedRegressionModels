---
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r, include=FALSE}
set.seed(42)
```

# Correlation structures {#correlation}

## General Idea

Except for the random effects, we have so far assumed that residual errors are independent. However, that must not always be the case - we may find that residuals show autocorrelation.

::: callout-note
Correlation means that one variable correlates with another. Autocorrelation means that data points of one variable that are close to each other have similar values. This implies that autocorrelation is only defined if there is a "distance relationship" between observations.
:::

Autocorrelation can always occur if we have a distance relationship between observations. Apart from random effects, where distance is expressed by group, common examples of continuous distance relationships include:

-   Random effects (distance = group)
-   Spatial distance.
-   Temporal distance.
-   Phylogenetic distance.

Here a visualization from <a href="https://onlinelibrary.wiley.com/doi/10.1111/ecog.02881" target="_blank" rel="noopener">Roberts et al., 2016</a> (reproduced as OA, copyright: the authors).

```{r chunk_chapter6_chunk0, echo=FALSE, out.width="100%", out.height="100%"}
knitr::include_graphics(c("images/correlation.png"))
```

### Models to deal with autocorrelation

If we find autocorrelation in the residuals of our model, there can be several reasons, which we can address by different structures.

::: callout-important
In the context of regression models, we are never interested in the autocorrelation of the response / predictors per se, but only in the residuals. Thus, it doesn't make sense to assume that you need a spatial model only because you have a spatially autocorrelated signal.
:::

1.  Autocorrelation can occur because we have a spatially correlated misfit, i.e. there is a **trend** in the given space (e.g. time, space, phylogeny). If this is the case, de-trending the model (with a linear regression term or a spline) will remove the residual autocorrelation. We should always de-trend first because we consider moving to a model with a residual correlation structure.

2.  Only after accounting for the trend, we should test if there is a residual spatial / temporal / phylogenetic **autocorrelation**. If that is the case, we would usually use a so-called **conditional autoregressive** (CAR) structures. In these models, we make parametric assumptions for how the correlation between data points falls off with distance. When we speak about spatial / temporal / phylogenetic regressions, we usually refer to these or similar models.

### R implementation

To de-trend, you can just use standard regression terms or splines on time or space. For the rest of this chapter, we will concentrate on how to specify "real" correlation structures. However, in the case studies, you should always de-trend first.

To account for "real" autocorrelation of residuals, similar as for the variance modelling, we can add correlation structures

-   for normal responses in `nlme::gls`{.R}, see <a href="https://stat.ethz.ch/R-manual/R-devel/library/nlme/html/corClasses.html" target="_blank" rel="noopener">https://stat.ethz.ch/R-manual/R-devel/library/nlme/html/corClasses.html</a>
-   for GLMs using `glmmTMB`{.R}, see <a href="https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html" target="_blank" rel="noopener">https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html</a>.

The following pages provide examples and further comments on how to do this.

::: callout-note
Especially for spatial models, both nlme and glmmTMB are relatively slow. Therea are a large number of specialized packages that deal in particular with the problem of spatial models, including `MASS::glmmPQL`, BRMS, INLA, spaMM, and many more. To keep things simple and concentrate on the principles, however, we will stick with the packages you already know.
:::

## Temporal Correlation Structures

To introduce temporal autoregressive models, let's simulate some data first. The most simple (and common) temporal structure is the AR1 model, aka autoregressive model with lag 1. The AR1 assumes that the next data point (or residual) originates from a weighted mean of the last data point and a residual normal distribution in the form

$$
x_{t+1} = a \cdot x_t + (1-a) \cdot \epsilon
$$

Let's simulate some data according to this model

```{r}
# simulate temporally autocorrelated data
AR1sim<-function(n, a){
  x = rep(NA, n)
  x[1] = 0
  for(i in 2:n){
    x[i] = a * x[i-1] + (1-a) * rnorm(1)
  }
  return(x)
}

set.seed(123)
obs = AR1sim(1000, 0.9)
plot(obs)
```

As we can see, we have a temporal correlation here. As we have not modeled / specified any further predictors, the correlation in the signal will transform directly in the correlations of the residuals if we fit a model:

```{r}
fit = lm(obs~1)
summary(fit)
```

Note that the estimate of the intercept is significant, although we started the simulation at zero. Let's look at the residuals, which have the same autocorrelation as the data.

```{r}
plot(residuals(fit))
```

We can quantify the autocorrelation by the acf function, which quantifies correlation between observations as a function of their lag (temporal distance). Note that although we modeled only a lag of 1, we will get correlations with many lags, because the correlation effect "trickles down".

```{r}
acf(residuals(fit))
```

To check what the actual underlying model is, it may be useful to plot the partial correlation coefficient, which is estimated by fitting autoregressive models of successively higher orders and checking their residuals.

```{r}
pacf(residuals(fit))
```

Here, we see that we actually only have a correlation with lag 1. You can also check for temporal correlation with the DHARMa package

```{r}
library(DHARMa)
testTemporalAutocorrelation(fit, time = 1:1000)
```

::: callout-note
Remember: in general, for spatial / temporal data, there are two processes that can created residual autocorreation:

1.  There is a spatial misfit trend in time / space, which creates a correlation in space / time.
2.  There truly is a spatial correlation, after accounting for the trend.

Unfortunately, the distinction between a larger trend and a correlation is quite fluid. Nevertheless, one should always first check for and remove the trend, typically by including time/space as a predictor, potentially in a flexible way (GAMs come in handy). After this is done, we can fit a model with a temporally/spatially correlated error.
:::

Let's see how we can fit the AR1 model to data. First, with nlme

```{r}
library(nlme)

fitGLS = gls(obs~1, corr = corAR1(0.771, form = ~ 1))
summary(fitGLS)
```

Second, with glmmTMB

```{r}
library(glmmTMB)

time <- factor(1:1000) # time variable
group = factor(rep(1,1000)) # group (for multiple time series)

fitGLMMTMB = glmmTMB(obs ~ ar1(time + 0 | group))
summary(fitGLMMTMB)
```

If you check the results, you can see that

1.  Both models correctly estimate the AR1 parameter
2.  The p-value for the intercept is in both models n.s., as expected

::: callout-note
#### Trend and autocorrelation with glmmTMB

As I mentioned earlier, first detrend and then add correlation structure if there is autocorrelation. After both steps we should no longer see any pattern in the conditional residuals. Unfortunately, checking the conditional residuals is a bit complicated because glmmTMB does not support conditional simulations, while lme4 does, but it does not support correlation structures. However, there is a workaround.

Let's start with a small simulation with a time trend and autocorrelation:

```{r}
time = 1:1000/100
y = time +2*(sin(time/0.4)) + rnorm(1000)
data = 
  data.frame(y = y, time = time, timeF = as.factor(1:1000), group = as.factor(1))
plot(y ~time)

```

1.  **Detrend**

```{r}
fit1 = glmmTMB(y~time, data = data)
res = simulateResiduals(fit1, plot = TRUE)
testTemporalAutocorrelation(res, time = data$time)
```

Test for temporal autocorrelation is siginificant -\> add autoregressive structure

2.  **Add autoregressive structure**

```{r}
fit2 = glmmTMB(y~time + ar1(0+timeF|group), data = data)
res = simulateResiduals(fit2, plot = TRUE)
```

The residual plot did not change because `glmmTMB:::simulate.glmmTMB` does not generate conditional predictions. But we can generate them ourselves:

3.  **Create conditional predictions and simulations**

We can create a custom DHARMa object with our own simulations:

```{r}
pred = predict(fit2, re.form = NULL)
simulations = sapply(1:250, function(i) rnorm(1000, pred, summary(fit2)$sigma))
res = createDHARMa(simulations, data$y, pred)
plot(res)
```

Voila, the residuals look good now!
:::

### Exercise - hurricanes revisited?

::: {.callout-caution icon="false"}
#### Excercise

Look at the hurricane study that we used before, which is, after all, temporal data. This data set is located in `DHARMa`{.R}.

```{r}
library(DHARMa)

fit = glmmTMB(alldeaths ~ scale(MasFem) *
                          (scale(Minpressure_Updated_2014) + scale(NDAM)),
                           data = hurricanes, family = nbinom2)

# Residual checks with DHARMa.
res = simulateResiduals(fit)

# Checking for temporal autocorrelation
res2 = recalculateResiduals(res, group = hurricanes$Year)
testTemporalAutocorrelation(res2, time = unique(hurricanes$Year))
```

We see that there is a tiny bit of autocorrelation. Note that this autocorrelation is negative, so if we have a higher residual in one year, it is lower in the next year. Normally, we would expect temporal autocorrelation to be positive, so this is a bit weird. It could be an effect of people being more careful if there mere many fatalities in the previous year, but it could also be a statistical fluke.

In any case, as an exercise, we want to address the issue - add an AR1 term to the model!
:::

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Solution

Adding the AR1 to the glmmTMB model

```{r}
hurricanes$yearF <- factor(hurricanes$Year)
hurricanes$group = factor(rep(1,nrow(hurricanes)))

fit = glmmTMB(alldeaths ~ scale(MasFem) *
                          (scale(Minpressure_Updated_2014) + scale(NDAM))
                          + ar1(yearF + 0 | group),
                           data = hurricanes, family = nbinom2)
summary(fit)
```

Careful, we are getting a convergence warning here! You should take these warnings seriously! If we look at the fitted values, we see that we estimate positive temporal autocorrelation, although the plots showed negative autocorrelation. Let's fit a reduced model:

```{r}
fit = glmmTMB(alldeaths ~ scale(MasFem) 
                          + ar1(yearF + 0 | group),
                           data = hurricanes, family = nbinom2)
summary(fit)
```

Now we get the right estimates for the autocorrelation, but of course this is not the model we want. You should now go to the optimizer settings and see if you can fix this. If you can't fix it, you could maybe
:::

## Spatial Correlation Structures

Spatial models work very similar to the temporal models. This time, we start directly with an example, using a data set with the thickness of coal seams, that we try to predict with a spatial (soil) predictor.

```{r}
library(EcoData)
plot(thick ~ soil, data = thickness)
```

Let's fit a simple LM to this

```{r}
fit = lm(thick ~ soil, data = thickness)
summary(fit)
```

DHARMa checks:

```{r}
res = simulateResiduals(fit)
testSpatialAutocorrelation(res, x = thickness$north, y = thickness$east)
```

For spatial data, we often look at spatial variograms, which are similar to an acf but in spatial directions

```{r}
library(gstat)
tann.dir.vgm = variogram(residuals(fit) ~ 1,
                         loc =~ east + north, data = thickness,
                         alpha = c(0, 45, 90, 135))
plot(tann.dir.vgm)
```

Both the DHARMa plots and the variograms are more indicative of a spatial trend. Let's remove this with a 2d-spine, called a tensor spline:

```{r chunk_chapter6_chunk5, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
library(mgcv)

fit1 = gam(thick ~ soil + te(east, north) , data = thickness)
summary(fit1)
plot(fit1, pages = 0, lwd = 2)
```

We can check the model again, and the problem is gone

```{r}
res = simulateResiduals(fit1)
testSpatialAutocorrelation(res, x = thickness$north, y = thickness$east)
```

Almost the same, but simpler:

```{r}
fit = lm(thick ~ soil + north + I(north^2), data = thickness)
```

If we would have still seen a signal, we should have fit an autoregressive model. Here it's not necessary, but just to show you the syntax - first nlme:

```{r chunk_chapter6_chunk7, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
fit2 = gls(thick ~ soil , correlation = corExp(form =~ east + north) , data = thickness)
summary(fit2)
```

Second, for glmmTMB. Here, we again have to prepare the data first

```{r}
thickness$pos <- numFactor(thickness$east, 
                           thickness$north)
thickness$group <- factor(rep(1, nrow(thickness)))

fit3 = glmmTMB(thick ~ soil + exp(pos + 0 | group) , data = thickness)
```

The output of summary is a bit chunky, which is why I suppress it here

```{r, eval = F}
summary(fit3)
```

If you wonder why there is such a large correlation matrix displayed: both the AR1 and the exp(pos + 0 \| group) structure impose a particular correlation structure on the random effects. Per default, glmmTMB shows correlations of random effects if they are estimated. In the case of the AR1 structure, the programmers apparently surpressed this, and just showed the stimate of the AR1 parameter. Here, however, they didn't implement this feature, so you see the entire correlation structure, which is, admittedly, less helpful and should be changed.

### Exercise - does agriculture influence plant species richness?

::: {.callout-caution icon="false"}
#### Plant counts in Regensburg

Use the dataset `EcoData::plantcounts`. Our scientific question is if richness \~ agrarea. Help on the dataset, as well as a few initial plots, is in the help of `?plantcounts`.

This is count data, so start with a Poisson or Neg Binom GLM. The quadrats are not all equally sized, so you should include an offest to account for area. Then, check for spatial autocorrelation.

If you find autocorrelation that cannot be removed with a gam, the problem is that the gls function that we have used so far only extends lm, and not glm models. In this case, you can either read up in https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html how to specify a spatial covariance in glmmTMB, or just log transform your counts + 1, and fit a gls.
:::

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Solution

```{r message=FALSE, warning=FALSE}
?EcoData::plantcounts

plants_sf <- plantcounts
str(plants_sf)
plants_sf$agrarea_scaled <- scale(plants_sf$agrarea)

plants_sf$longitude <- plants_sf$lon
plants_sf$latitude <- plants_sf$lat
library(sf)
plants_sf <- sf::st_as_sf(plants_sf, coords = c('longitude', 'latitude'), crs
                          = st_crs("+proj=longlat +ellps=bessel
                                   +towgs84=606,23,413,0,0,0,0 +no_defs"))

library(mapview)
mapview(plants_sf["richness"], map.types = "OpenTopoMap")

fit <-  glmmTMB::glmmTMB(richness ~ agrarea_scaled + offset(log(area)),
                family = nbinom1, data = plants_sf)
summary(fit)

library(DHARMa)
res <- simulateResiduals(fit)
plot(res)
testSpatialAutocorrelation(res, x = plants_sf$lon, y =  plants_sf$lat)

fit2<-mgcv::gam(richness ~ agrarea_scaled + te(lon, lat),
            offset(log(area)), family = nb, data = plants_sf)
summary(fit2)
plot(fit2)

library(mgcViz)
b <- getViz(fit2)
print(plot(b, allTerms = F), pages = 1) # Calls print.plotGam()

#plotRGL(sm(b, 1), residuals = TRUE)

res <- simulateResiduals(fit2)
plot(res)
testSpatialAutocorrelation(res, x = plants_sf$lon, y =  plants_sf$lat)
```
:::

## Phylogenetic Structures (PGLS)

This is mostly taken from <a href="https://lukejharmon.github.io/ilhabela/instruction/2015/07/03/PGLS/" target="_blank" rel="noopener">https://lukejharmon.github.io/ilhabela/instruction/2015/07/03/PGLS/</a>. The two datasets associated with this example are in the `EcoData`{.R} package.

Perform analysis:

```{r chunk_chapter6_chunk8, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
library(EcoData)
library(ape)
library(geiger)
library(nlme)
library(phytools)
library(DHARMa)
```

To plot the phylogenetic tree, use

```{r chunk_chapter6_chunk9, eval=FALSE, fig.width=8, fig.height=18}
plot(anolisTree)
```

Regress species traits

```{r}
# Check whether names are matching in both files.
name.check(anolisTree, anolisData)

# Plot traits.
plot(anolisData[, c("awesomeness", "hostility")])

plot(hostility ~ awesomeness, data = anolisData)
fit = lm(hostility ~ awesomeness, data = anolisData)
summary(fit)
abline(fit)
```

Check for phylogenetic signal in residuals.

```{r}
# Calculate weight matrix for phylogenetic distance.
w = 1/cophenetic(anolisTree)
diag(w) = 0

Moran.I(residuals(fit), w)
```

Conclusion: signal in the residuals, a normal lm will not work.

You can also check with DHARMa, using this works also for GLMMs

```{r}
res = simulateResiduals(fit)
testSpatialAutocorrelation(res, distMat = cophenetic(anolisTree))
```

An old-school method to deal with the problem are the so-called **Phylogenetically Independent Contrasts** (PICs) (Felsenstein, J. (1985) "Phylogenies and the comparative method". American Naturalist, 125, 1--15.). The idea here is to transform your data in a way that an lm is still appropriate. For completeness, I show the method here.

```{r chunk_chapter6_chunk12, echo=TRUE, eval=TRUE}
# Extract columns.
host = anolisData[, "hostility"]
awe = anolisData[, "awesomeness"]

# Give them names.
names(host) = names(awe) = rownames(anolisData)

# Calculate PICs.
hPic = pic(host, anolisTree)
aPic = pic(awe, anolisTree)

# Make a model.
picModel = lm(hPic ~ aPic - 1)

summary(picModel) # Yes, significant.

# plot results.
plot(hPic ~ aPic)
abline(a = 0, b = coef(picModel))
```

Now, new school, with a PGLS

```{r chunk_chapter6_chunk13, echo=TRUE, eval=TRUE}
pglsModel = gls(hostility ~ awesomeness,
                 correlation = corBrownian(phy = anolisTree, form =~ species),
                 data = anolisData, method = "ML")
summary(pglsModel)
coef(pglsModel)
plot(hostility ~ awesomeness, data = anolisData)
abline(pglsModel, col = "red")
```

OK, same result, but PGLS is WAY more flexible than PICs. For example, we can include a discrete predictor:

```{r chunk_chapter6_chunk14, echo=TRUE, eval=TRUE}
pglsModel2 = gls(hostility ~ ecomorph,
                    correlation = corBrownian(phy = anolisTree, form =~ species),
                    data = anolisData, method = "ML")
summary(pglsModel2)
anova(pglsModel2)

# We can even include multiple predictors:

pglsModel3 = gls(hostility ~ ecomorph * awesomeness,
                correlation = corBrownian(phy = anolisTree, form =~ species),
                data = anolisData, method = "ML")
summary(pglsModel3)
anova(pglsModel3)
```

We can also assume that the error structure follows an **Ornstein-Uhlenbeck** model rather than **Brownian motion**. When trying this, however, I noted that the model does not converge due to a scaling problem. We can do a quick fix by making the branch lengths longer. This will not affect the analysis other than rescaling a nuisance parameter.

```{r chunk_chapter6_chunk15, echo=TRUE, eval=TRUE}
tempTree = anolisTree
tempTree$edge.length = tempTree$edge.length * 100
pglsModelLambda = gls(hostility ~ awesomeness,
                      correlation = corPagel(1, phy = tempTree, fixed = FALSE,
                                             form =~ species),
                      data = anolisData, method = "ML")
summary(pglsModelLambda)

pglsModelOU = gls(hostility ~ awesomeness,
                   correlation = corMartins(1, phy = tempTree, form =~ species),
                   data = anolisData)
summary(pglsModelOU)
```

Other example: <a href="http://schmitzlab.info/pgls.htmla" target="_blank" rel="noopener">http://schmitzlab.info/pgls.html</a>.

For fitting PGLS with various models, you should also consider the `caper`{.R} package.

### Exercise - Does bird song change with altitude?

#### Excercise

::: {.callout-caution icon="false"}
The following exercise uses data from a study by Corboda et al., 2017, which examined the influence of environmental factors on the evolution of song in an group of Asian bird species called "barbets." The following code cleans the raw data available from the EcoData package:

```{r, eval = T}
library(ape)
library(EcoData)

dat = barbetData
tree = barbetTree

dat$species = row.names(dat)
plot(tree)

# dropping species in the phylogeny for which we don't have data
obj<-geiger::name.check(tree,dat)
reducedTree<-drop.tip(tree, obj$tree_not_data)
geiger::name.check(reducedTree,dat)
```

Task: Check if there is a relationship between altitude at which a species is found and the length of the note in its song, which uses the variables Lnote\~Lnalt
:::

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
#### Solution

```{r}
plot(Lnote~Lnalt, data = dat)
fit <- lm(Lnote~ scale(Lnalt), data = dat)
summary(fit)
library(effects)
plot(allEffects(fit,partial.residuals = T))
```

Bit of a misfit, to get a good fit, after playing around, I logged the response and added a quadratic and a cubic effect - you can probably also find other solutions.

```{r}
fit <- lm(log(Lnote) ~ scale(Lnalt) + I(scale(Lnalt)^2) + I(scale(Lnalt)^3), data = dat)
summary(fit)
plot(allEffects(fit,partial.residuals = T))
```

Now, with a more complex polynomial for Lnalt, how to we see if there is an overall effect of Lnalt? Easiest option is to do a LRT:

```{r}
fit0 = lm(log(Lnote)~ 1, data = dat)
anova(fit0, fit)
```

Check residuals for phylogenetic correlation

```{r}
w = 1/cophenetic(reducedTree)
diag(w) = 0
Moran.I(residuals(fit), w)
```

Nothing! So we could leave the model as it is. Just for completeness, fit the same comparison with a PGLS, effect remains significant, but p-value a bit larger.

```{r}
fit <- gls(Lnote~ scale(Lnalt) * I(scale(Lnalt)^2), 
           correlation = corBrownian(phy = reducedTree, 
                                     form =~ species), data = dat, 
           method = "ML")
summary(fit)
```

Btw, did you notice that neither Lnalt has a significant effect - so is there no dependence on Lnalt? Because we have the linear and quadaratic effect, the best way to answer this is to run an ANOVA:

```{r}
fit0 <- gls(Lnote~ 1, 
           correlation = corBrownian(phy = reducedTree, 
                                     form =~ species), data = dat, 
           method = "ML")

anova(fit0, fit)
```

which tells us that Lnalt has a significant effect, even though we can't reject that either the linear or the quadrart term is zero.

Addition: what would happen if we do the same with a misspecified model? Have a look at the p-values of the fitted models. Can you explain what's going on here?

```{r}
fit <- lm(Lnote~ scale(Lnalt), data = dat)
summary(fit)

plot(allEffects(fit, partial.residuals = T))

w = 1/cophenetic(reducedTree)
diag(w) = 0
Moran.I(residuals(fit), w)

fit <- gls(Lnote~ scale(Lnalt), 
           correlation = corBrownian(phy = reducedTree, 
                                     form =~ species), data = dat, 
           method = "ML")
summary(fit)
```

The observation is that the PGLS effect estimate is significant while normal lm is not. The reason is probably that the PGLS is re-weighting residuals, and it seems that in this case, the re-weighting is changing the slope. What we learn by this example is that a PGLS can increase significance, and in this case I would argue wrongly so, as we have no indication that there is a phylogenetic signal. I would therefore NOT recommend to blindly fit PGLS, but rather test first if a PGLS is needed, and only then apply.
:::

## Multivariate GLMs

In the recent years, multivariate GLMs, in particular the multivariate probit model, and latent variable versions thereof, have become popular for the analysis of community data. The keyword here is "joint species distribution models" (jSDMs).

Briefly, what we want a jSDM to do is to fit a vector of responses (could be abundance or presence / absence data) as a function of environmental predictors and a covariance between the responses. The model is thus

$$
y \sim f(x) + \Sigma
$$ where y is a response vector, f(x) is a matrix with effects, and $\Sigma$ is a covariance matrix that we want to estimate.

You can fit these models directly in lme4 or glmmTMB via implementing an RE per species

```{r, eval = F}
lme4(abundance ~ 0 + species + env:species + (0+species|site)
glmmTMB(abundance ~ 0 + species + env:species + (0+species|site)
```

however, these so-called full-rank models have a lot of degrees of freedom and are slow to compute if the number of species gets large. It has therefore become common to fit rank-reduced versions of the these models using a latent-variable reparameterization of the model above. A latent-variable version of this model can be fit in glmmTMB via this syntax

```{r, eval = F}
glmmTMB(abundance ~ 0 + species + env:species + rr(Species + 0|id, d = 2))
```

The parameter d controlls the number of latent variables.

Of course, there are many more specialized packages for fitting latent-variable jSDMs in R right now, including hmsc, gllvm or sjSDM, but I find it nice to set this models in the general topic of correlations, and realize that we can fit them with the same methods and packages as for all other correlation structures.
